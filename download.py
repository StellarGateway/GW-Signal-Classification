import os
import time
import pandas as pd
import numpy as np
from gwpy.timeseries import TimeSeries
import requests
import io

# --- config ---
BASE_PATH = 'data'
DETECTORS = ['H1', 'L1']

# Signal Config
SIGNAL_CATALOGS = ['GWTC-1-confident', 'GWTC-2.1-confident', 'GWTC-3-confident']
SIGNAL_DURATION = 32
SIGNAL_SAMPLE_RATE = 4096

# Glitch Config
GLITCH_METADATA_FILES = [
    'O3a_H1.csv', 'O3a_L1.csv', 'O3b_H1.csv', 'O3b_L1.csv'
]
GLITCH_CLASSES = [
    "Blip", "Koi_Fish", "Tomte", "Whistle", "Scratching",
    "Power_Line", "No_Glitch", "Light_Modulation"
]

#reduced number of glitches per class for testing
NUM_GLITCHES_PER_CLASS = 150
GLITCH_DURATION = 4
GLITCH_SAMPLE_RATE = 4096


def setup_directories():
    """Creates the directory structure for storing the datasets."""
    print("--- Setting up directories ---")
    for split in ['train', 'validation', 'test']:
        os.makedirs(os.path.join(BASE_PATH, 'signals', split), exist_ok=True)
        os.makedirs(os.path.join(BASE_PATH, 'glitches', split), exist_ok=True)
    print("Directory setup complete.\n")


def download_real_signals():
    """Downloads and classifies real signals from multiple GWOSC catalogs."""
    print("--- Downloading Real Signal Data (BBH and BNS) ---")
    all_events = []
    for catalog in SIGNAL_CATALOGS:
        try:
            catalog_url = f'https://gwosc.org/eventapi/csv/{catalog}/'
            print(f"Fetching catalog: {catalog}")
            response = requests.get(catalog_url).content
            df = pd.read_csv(io.StringIO(response.decode('utf-8')))
            df.rename(columns={'gps': 'GPS', 'commonName': 'name'}, inplace=True)
            all_events.append(df)
        except Exception as e:
            print(f"  - Could not fetch or process {catalog}. Error: {e}")

    if not all_events:
        print("FATAL: No event catalogs could be downloaded. Exiting signal download.")
        return

    events_df = pd.concat(all_events, ignore_index=True).drop_duplicates(subset=['name']).set_index('name')
    events_df = events_df.dropna(subset=['mass_1_source', 'mass_2_source', 'GPS'])
    events_df['type'] = np.where(
        (events_df['mass_1_source'] < 3) & (events_df['mass_2_source'] < 3), 'BNS', 'BBH'
    )
    print(f"\nFound {len(events_df)} total unique events across all catalogs.")
    print(events_df['type'].value_counts())

    shuffled_df = events_df.sample(frac=1)
    train_df, val_df, test_df = np.split(shuffled_df, [int(.8*len(shuffled_df)), int(.9*len(shuffled_df))])
    splits = {'train': train_df, 'validation': val_df, 'test': test_df}

    for split_name, df in splits.items():
        print(f"\nProcessing {split_name} set ({len(df)} events)...")
        for name, row in df.iterrows():
            for detector in DETECTORS:
                try:
                    #wait 1 second to avoid network issues
                    time.sleep(1)
                    
                    gps_int = int(row['GPS'])
                    t0, t1 = gps_int - (SIGNAL_DURATION // 2), gps_int + (SIGNAL_DURATION // 2)
                    filename = f"{row['type']}_{detector}_{gps_int}.gwf"
                    filepath = os.path.join(BASE_PATH, 'signals', split_name, filename)
                    if os.path.exists(filepath): continue
                    
                    print(f"  Downloading {row['type']} {name} for {detector}...")
                    data = TimeSeries.fetch_open_data(detector, t0, t1, sample_rate=SIGNAL_SAMPLE_RATE, cache=True)
                    data.write(filepath)
                except Exception as e:
                    print(f"    - Could not download {row['type']} {name} for {detector}: {e}")

def download_glitch_data():
    """Downloads glitch data using the public Gravity Spy metadata from Zenodo."""
    print("\n--- Downloading Glitch Data from Public Gravity Spy Dataset ---")
    
    # base URL Zenodo 
    zenodo_base_url = "https://zenodo.org/record/5649212/files/"
    
    all_glitches = []
    for filename in GLITCH_METADATA_FILES:
        try:
            metadata_url = f"{zenodo_base_url}{filename}"
            print(f"Fetching glitch metadata from: {metadata_url}")
            df = pd.read_csv(metadata_url)
            # Standardize column names
            df.rename(columns={'peak_time': 'GPS', 'ifo': 'detector', 'label':'type'}, inplace=True)
            all_glitches.append(df)
        except Exception as e:
            print(f"  - Could not read metadata from {filename}. Error: {e}")
            
    if not all_glitches:
        print("FATAL: No glitch metadata could be downloaded. Exiting glitch download.")
        return
        
    glitches_df = pd.concat(all_glitches, ignore_index=True)
    print(f"\nFound metadata for {len(glitches_df)} total glitches.")
    
    #split dataset
    shuffled_df = glitches_df.sample(frac=1)
    train_df, val_df, test_df = np.split(shuffled_df, [int(.8*len(shuffled_df)), int(.9*len(shuffled_df))])
    splits = {'train': train_df, 'validation': val_df, 'test': test_df}

    for split_name, df in splits.items():
        print(f"\nProcessing {split_name} set ({len(df)} glitches)...")
        for g_class in GLITCH_CLASSES:
            class_df = df[df['type'] == g_class]
            sample_df = class_df.sample(n=min(len(class_df), NUM_GLITCHES_PER_CLASS // 3)) #
            
            print(f"  Downloading {len(sample_df)} '{g_class}' glitches...")
            for _, row in sample_df.iterrows():
                try:
                    # NETWORK FIX: Wait 1 second
                    time.sleep(1)
                    
                    detector = row['detector']
                    gps_int = int(row['GPS'])
                    
                    t0, t1 = gps_int - (GLITCH_DURATION // 2), gps_int + (GLITCH_DURATION // 2)
                    out_filename = f"{g_class}_{detector}_{gps_int}.gwf"
                    filepath = os.path.join(BASE_PATH, 'glitches', split_name, out_filename)
                    if os.path.exists(filepath): continue
                    
                    data = TimeSeries.fetch_open_data(detector, t0, t1, sample_rate=GLITCH_SAMPLE_RATE, cache=True)
                    data.write(filepath)
                except Exception as e:
                    print(f"    - Could not download glitch at {row['GPS']}: {e}")

if __name__ == '__main__':
    # Ensure you have these installed: pip install gwpy pandas numpy requests tables
    setup_directories()
    download_real_signals()
    download_glitch_data()
    print("\n==========================")
    print("Data download complete.")
    print(f"All data has been saved to the '{BASE_PATH}' directory.")
    print("==========================")
    
    
# OUTPUT:
# --- Setting up directories ---
# Directory setup complete.

# --- Downloading Real Signal Data (BBH and BNS) ---
# Fetching catalog: GWTC-1-confident
# Fetching catalog: GWTC-2.1-confident
# Fetching catalog: GWTC-3-confident

# Found 90 total unique events across all catalogs.
# type
# BBH    88
# BNS     2
# Name: count, dtype: int64
# /opt/anaconda3/envs/gw/lib/python3.11/site-packages/numpy/_core/fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.
#   return bound(*args, **kwds)

# Processing train set (72 events)...
#   Downloading BBH GW190503_185404 for H1...
#   Downloading BBH GW190503_185404 for L1...
#   Downloading BBH GW190517_055101 for H1...
#   Downloading BBH GW190517_055101 for L1...
#   Downloading BBH GW190916_200658 for H1...
#   Downloading BBH GW190916_200658 for L1...
#   Downloading BBH GW190521 for H1...
#   Downloading BBH GW190521 for L1...
#   Downloading BBH GW190403_051519 for H1...
#   Downloading BBH GW190403_051519 for L1...
#   Downloading BBH GW200306_093714 for H1...
#   Downloading BBH GW200306_093714 for L1...
#   Downloading BBH GW190620_030421 for H1...
#     - Could not download BBH GW190620_030421 for H1: Cannot find a GWOSC dataset for H1 covering [1245035063, 1245035095)
#   Downloading BBH GW190620_030421 for L1...
#   Downloading BBH GW191127_050227 for H1...
#   Downloading BBH GW191127_050227 for L1...
#   Downloading BBH GW170809 for H1...
#   Downloading BBH GW170809 for L1...
#   Downloading BBH GW200112_155838 for H1...
#     - Could not download BBH GW200112_155838 for H1: Cannot find a GWOSC dataset for H1 covering [1262879920, 1262879952)
#   Downloading BBH GW200112_155838 for L1...
#   Downloading BBH GW200225_060421 for H1...
#   Downloading BBH GW200225_060421 for L1...
#   Downloading BBH GW190426_190642 for H1...
#   Downloading BBH GW190426_190642 for L1...
#   Downloading BBH GW170814 for H1...
#   Downloading BBH GW170814 for L1...
#   Downloading BBH GW190805_211137 for H1...
#   Downloading BBH GW190805_211137 for L1...
#   Downloading BBH GW200220_124850 for H1...
#   Downloading BBH GW200220_124850 for L1...
#   Downloading BNS GW190425 for H1...
#   Downloading BNS GW190425 for L1...
#   Downloading BBH GW190708_232457 for H1...
#     - Could not download BBH GW190708_232457 for H1: Cannot find a GWOSC dataset for H1 covering [1246663499, 1246663531)
#   Downloading BBH GW190708_232457 for L1...
#   Downloading BBH GW190630_185205 for H1...
#     - Could not download BBH GW190630_185205 for H1: Cannot find a GWOSC dataset for H1 covering [1245955927, 1245955959)
#   Downloading BBH GW190630_185205 for L1...
#   Downloading BBH GW200216_220804 for H1...
#   Downloading BBH GW200216_220804 for L1...
#   Downloading BBH GW170104 for H1...
#   Downloading BBH GW170104 for L1...
#   Downloading BBH GW190413_134308 for H1...
#   Downloading BBH GW190413_134308 for L1...
#   Downloading BBH GW191109_010717 for H1...
#   Downloading BBH GW191109_010717 for L1...
#   Downloading BBH GW200208_222617 for H1...
#   Downloading BBH GW200208_222617 for L1...
#   Downloading BBH GW200210_092254 for H1...
#   Downloading BBH GW200210_092254 for L1...
#   Downloading BBH GW190930_133541 for H1...
#   Downloading BBH GW190930_133541 for L1...
#   Downloading BBH GW190513_205428 for H1...
#   Downloading BBH GW190513_205428 for L1...
#   Downloading BBH GW190701_203306 for H1...
#   Downloading BBH GW190701_203306 for L1...
#   Downloading BBH GW190413_052954 for H1...
#   Downloading BBH GW190413_052954 for L1...
#   Downloading BBH GW191230_180458 for H1...
#   Downloading BBH GW191230_180458 for L1...
#   Downloading BBH GW191103_012549 for H1...
#   Downloading BBH GW191103_012549 for L1...
#   Downloading BBH GW190412 for H1...
#   Downloading BBH GW190412 for L1...
#   Downloading BBH GW190929_012149 for H1...
#   Downloading BBH GW190929_012149 for L1...
#   Downloading BBH GW200322_091133 for H1...
#   Downloading BBH GW200322_091133 for L1...
#   Downloading BBH GW191216_213338 for H1...
#   Downloading BBH GW191216_213338 for L1...
#     - Could not download BBH GW191216_213338 for L1: Cannot find a GWOSC dataset for L1 covering [1260567220, 1260567252)
#   Downloading BBH GW170818 for H1...
#   Downloading BBH GW170818 for L1...
#   Downloading BBH GW190719_215514 for H1...
#   Downloading BBH GW190719_215514 for L1...
#   Downloading BBH GW191222_033537 for H1...
#   Downloading BBH GW191222_033537 for L1...
#   Downloading BBH GW190926_050336 for H1...
#   Downloading BBH GW190926_050336 for L1...
#   Downloading BBH GW190725_174728 for H1...
#   Downloading BBH GW190725_174728 for L1...
#   Downloading BBH GW190727_060333 for H1...
#   Downloading BBH GW190727_060333 for L1...
#   Downloading BBH GW190707_093326 for H1...
#   Downloading BBH GW190707_093326 for L1...
#   Downloading BBH GW190803_022701 for H1...
#   Downloading BBH GW190803_022701 for L1...
#   Downloading BBH GW200302_015811 for H1...
#   Downloading BBH GW200302_015811 for L1...
#     - Could not download BBH GW200302_015811 for L1: Cannot find a GWOSC dataset for L1 covering [1267149493, 1267149525)
#   Downloading BBH GW200224_222234 for H1...
#   Downloading BBH GW200224_222234 for L1...
#   Downloading BBH GW191204_171526 for H1...
#   Downloading BBH GW191204_171526 for L1...
#   Downloading BBH GW190828_063405 for H1...
#   Downloading BBH GW190828_063405 for L1...
#   Downloading BBH GW190731_140936 for H1...
#   Downloading BBH GW190731_140936 for L1...
#   Downloading BBH GW190512_180714 for H1...
#   Downloading BBH GW190512_180714 for L1...
#   Downloading BBH GW190910_112807 for H1...
#   Downloading BBH GW190910_112807 for L1...
#   Downloading BBH GW191126_115259 for H1...
#   Downloading BBH GW191126_115259 for L1...
#   Downloading BBH GW190408_181802 for H1...
#   Downloading BBH GW190408_181802 for L1...
#   Downloading BBH GW190521_074359 for H1...
#   Downloading BBH GW190521_074359 for L1...
#   Downloading BBH GW170729 for H1...
#   Downloading BBH GW170729 for L1...
#   Downloading BBH GW191219_163120 for H1...
#   Downloading BBH GW191219_163120 for L1...
#   Downloading BBH GW190527_092055 for H1...
#   Downloading BBH GW190527_092055 for L1...
#   Downloading BBH GW190602_175927 for H1...
#   Downloading BBH GW190602_175927 for L1...
#   Downloading BBH GW191129_134029 for H1...
#   Downloading BBH GW191129_134029 for L1...
#   Downloading BBH GW190917_114630 for H1...
#   Downloading BBH GW190917_114630 for L1...
#   Downloading BBH GW190828_065509 for H1...
#   Downloading BBH GW190828_065509 for L1...
#   Downloading BBH GW200209_085452 for H1...
#   Downloading BBH GW200209_085452 for L1...
#   Downloading BBH GW190514_065416 for H1...
#   Downloading BBH GW190514_065416 for L1...
#   Downloading BBH GW190814 for H1...
#   Downloading BBH GW190814 for L1...
#   Downloading BBH GW190519_153544 for H1...
#   Downloading BBH GW190519_153544 for L1...
#   Downloading BBH GW190421_213856 for H1...
#   Downloading BBH GW190421_213856 for L1...
#   Downloading BBH GW170608 for H1...
#   Downloading BBH GW170608 for L1...
#   Downloading BBH GW191105_143521 for H1...
#   Downloading BBH GW191105_143521 for L1...
#   Downloading BBH GW191215_223052 for H1...
#   Downloading BBH GW191215_223052 for L1...
#   Downloading BNS GW170817 for H1...
#   Downloading BNS GW170817 for L1...
#   Downloading BBH GW200202_154313 for H1...
#   Downloading BBH GW200202_154313 for L1...
#   Downloading BBH GW200220_061928 for H1...
#   Downloading BBH GW200220_061928 for L1...
#   Downloading BBH GW151012 for H1...
#   Downloading BBH GW151012 for L1...
#   Downloading BBH GW200219_094415 for H1...
#   Downloading BBH GW200219_094415 for L1...

# Processing validation set (9 events)...
#   Downloading BBH GW191113_071753 for H1...
#   Downloading BBH GW191113_071753 for L1...
#   Downloading BBH GW191204_110529 for H1...
#   Downloading BBH GW191204_110529 for L1...
#   Downloading BBH GW200308_173609 for H1...
#   Downloading BBH GW200308_173609 for L1...
#   Downloading BBH GW200208_130117 for H1...
#   Downloading BBH GW200208_130117 for L1...
#   Downloading BBH GW200311_115853 for H1...
#   Downloading BBH GW200311_115853 for L1...
#   Downloading BBH GW200129_065458 for H1...
#   Downloading BBH GW200129_065458 for L1...
#   Downloading BBH GW190924_021846 for H1...
#   Downloading BBH GW190924_021846 for L1...
#   Downloading BBH GW190720_000836 for H1...
#   Downloading BBH GW190720_000836 for L1...
#   Downloading BBH GW190728_064510 for H1...
#   Downloading BBH GW190728_064510 for L1...

# Processing test set (9 events)...
#   Downloading BBH GW200115_042309 for H1...
#   Downloading BBH GW200115_042309 for L1...
#   Downloading BBH GW151226 for H1...
#   Downloading BBH GW151226 for L1...
#   Downloading BBH GW150914 for H1...
#   Downloading BBH GW150914 for L1...
#   Downloading BBH GW170823 for H1...
#   Downloading BBH GW170823 for L1...
#   Downloading BBH GW190706_222641 for H1...
#   Downloading BBH GW190706_222641 for L1...
#   Downloading BBH GW190915_235702 for H1...
#   Downloading BBH GW190915_235702 for L1...
#   Downloading BBH GW200128_022011 for H1...
#   Downloading BBH GW200128_022011 for L1...
#   Downloading BBH GW190925_232845 for H1...
#   Downloading BBH GW190925_232845 for L1...
#     - Could not download BBH GW190925_232845 for L1: Cannot find a GWOSC dataset for L1 covering [1253489327, 1253489359)
#   Downloading BBH GW200316_215756 for H1...
#   Downloading BBH GW200316_215756 for L1...

# --- Downloading Glitch Data from Public Gravity Spy Dataset ---
# Fetching glitch metadata from: https://zenodo.org/record/5649212/files/O3a_H1.csv
#   - Could not read metadata from O3a_H1.csv. Error: HTTP Error 404: NOT FOUND
# Fetching glitch metadata from: https://zenodo.org/record/5649212/files/O3a_L1.csv
#   - Could not read metadata from O3a_L1.csv. Error: HTTP Error 404: NOT FOUND
# Fetching glitch metadata from: https://zenodo.org/record/5649212/files/O3b_H1.csv
#   - Could not read metadata from O3b_H1.csv. Error: HTTP Error 404: NOT FOUND
# Fetching glitch metadata from: https://zenodo.org/record/5649212/files/O3b_L1.csv
#   - Could not read metadata from O3b_L1.csv. Error: HTTP Error 404: NOT FOUND
# FATAL: No glitch metadata could be downloaded. Exiting glitch download.

# ==========================
# Data download complete.
